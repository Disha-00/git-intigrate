A Full end to end solution using Fabric Lakehouse

0- Create a Fabric Workspace

1- Create a lakehouse

2-Download the notebook from Github and import it to Fabric Workspace

3-open a notebook, attached it to the Lakehouse

4-Run the notebook in sequence just to have the initial load

Build your semantic Model in PowerBI when using Direct Lake

Alternatively, use this template for import mode

<img width="565" alt="image" src="https://github.com/djouallah/aemo_fabric/assets/12554469/d6f9ef5c-641e-4849-9d99-139275023cdd">

add a schedule for those notebooks

<img width="733" alt="image" src="https://github.com/djouallah/aemo_fabric/assets/12554469/62a5ac05-34b7-4ad8-af74-6d8d92a211a3">

